{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cProfile\n",
    "import os\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from skimage import data, img_as_float\n",
    "from skimage import measure\n",
    "import math\n",
    "from tf_unet import unet, util, image_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.data_set = dicom.dcmread(name)\n",
    "        \n",
    "    def get_Image(self):\n",
    "        #returns pixel array of the image\n",
    "        return self.data_set.pixel_array\n",
    "    \n",
    "    def get_Kspace(self,flip):\n",
    "        #returns flipped k-space data\n",
    "        data = self.get_Image()\n",
    "        arr = np.fft.fft2(data)\n",
    "        return arr if not flip else np.fft.fftshift(arr)\n",
    "    \n",
    "    def skipEveryNLine(self,N,img):\n",
    "        data = img\n",
    "        step = N\n",
    "        i = 0\n",
    "        count = 0\n",
    "        while i < int(len(data)):\n",
    "            for j in range (0,int(len(data[i]))):\n",
    "                data[i][j]=0\n",
    "            count+=1\n",
    "            if(count>=N):\n",
    "                count = 0\n",
    "                i= (i+2) if i < int(len(data))else i\n",
    "            else:\n",
    "                i= (i+1) if i < int(len(data))else i\n",
    "        return data  \n",
    "\n",
    "    def grappaUndersample(self,accelaration_factor,centerline_factor):\n",
    "        #undersamples top and bottom imagex \n",
    "        flipped_Img = self.get_Kspace(True)\n",
    "        center_line = int(len(flipped_Img)/2)\n",
    "        centerline_factor = len(flipped_Img)/centerline_factor\n",
    "        \n",
    "        upper_border = int(center_line - ( len(flipped_Img)/centerline_factor)/2)\n",
    "        lower_border = int(center_line + ( len(flipped_Img)/centerline_factor)/2)\n",
    "        \n",
    "        upSubsample = None\n",
    "        downSubsample = None\n",
    "        \n",
    "        if(accelaration_factor == 0):\n",
    "            upSubsample = np.zeros((upper_border,320), dtype=int)\n",
    "            downSubsample = np.zeros((upper_border,320), dtype=int)\n",
    "        else:\n",
    "            upSubsample = self.skipEveryNLine(accelaration_factor,flipped_Img[0:upper_border])\n",
    "            downSubsample = self.skipEveryNLine(accelaration_factor,flipped_Img[lower_border+1:])\n",
    "         \n",
    "        return np.concatenate((upSubsample,flipped_Img[upper_border:lower_border+1] ,downSubsample))\n",
    "    \n",
    "    def showImage(self,img,inFourierDomain,title):\n",
    "        if not inFourierDomain:\n",
    "            plt.imshow(np.absolute(Img), cmap=plt.cm.bone), plt.title(title,plt.axis('off'))\n",
    "            \n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.axis('off')\n",
    "            plt.imshow(np.log(1+np.absolute(Img)), cmap=plt.cm.bone), plt.title(\"Original Image\")\n",
    "            plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourierTransform(img):\n",
    "    data = img\n",
    "    arr = np.fft.fft2(data)  \n",
    "    return arr\n",
    "\n",
    "def inverseFourierTransform(img):\n",
    "    data = img\n",
    "    fourierTransformImg = np.fft.ifft2(data)\n",
    "    return fourierTransformImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def importDataset(path):\n",
    "    dcm_files = [path + '/' + f for f in listdir(path) if isfile(join(path, f))]\n",
    "    Images =  [Image(f) for f in dcm_files]\n",
    "    return Images\n",
    "def showImg(Img,inFourierDomain):\n",
    "        if not inFourierDomain:\n",
    "            plt.imshow(np.absolute(Img), cmap=plt.cm.bone), plt.title(\"Original Image\",plt.axis('off'))\n",
    "            \n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.axis('off')\n",
    "            plt.imshow(np.log(1+np.absolute(Img)), cmap=plt.cm.bone), plt.title(\"Original Image\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dataset using the function below. Define path to the training dataset folder on \"mypath\" parameter and path to testing folder on \"test Path\" parameter. The function returns a set of Image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = './brain_original'\n",
    "testPath = './brain_test/'\n",
    "\n",
    "datasets = importDataset(mypath)\n",
    "test_datasets = importDataset(testPath)[:5]\n",
    "dataset_shape = len(datasets[0].get_Image())\n",
    "dataset_column = len(datasets[0].get_Image()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(dataset,AF):\n",
    "    #edge cases \n",
    "    if not dataset:\n",
    "        raise Exception(\"Input a valid dataset\")\n",
    "    \n",
    "    if not AF: \n",
    "        raise Exception(\"Enter an accelaration factor\")\n",
    "        \n",
    "    if any ((x>4 or x<0) for x in AF):\n",
    "        raise Exception(\"The model only trains accelaration factors in the range of x where 0 <= x <= 4\")\n",
    "        \n",
    "    x_train = None\n",
    "    y_train = None\n",
    "       \n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(AF)):\n",
    "            if not np.any(x_train) and not np.any(y_train) :\n",
    "                x_train = np.absolute(dataset[0].get_Image())\n",
    "                y_train = np.absolute(inverseFourierTransform(dataset[0].grappaUndersample(AF[0],20)))\n",
    "            \n",
    "            else:\n",
    "                x_train = np.vstack([x_train,np.absolute(dataset[i].get_Image())])\n",
    "                y_train = np.vstack([y_train,np.absolute(inverseFourierTransform(dataset[i].grappaUndersample(AF[j],20)))])\n",
    "    \n",
    "    x_train = x_train.reshape(len(dataset)*len(AF),320,320,1)\n",
    "    y_train = y_train.reshape(len(dataset)*len(AF),320,320,1)\n",
    "    return (x_train,y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Working model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the model made for the thesis project run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./functional_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, concatenate, UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.losses import mean_squared_error, mean_absolute_error\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uNet:\n",
    "    def __init__(self,activation):\n",
    "        self.hasArchitecture = False\n",
    "        self.model = None\n",
    "        self.activation = activation \n",
    "        self.history = None\n",
    "        self.kernels = (3,3)\n",
    "        self.strides = (1,1)\n",
    "    \n",
    "    def set_model(self,model):\n",
    "        self.model = model\n",
    "        self.hasArchitecture = True\n",
    "        self.history = model.history\n",
    "    \n",
    "    def train(self,subsampled,original,batch_size,num_ephocs,checkpoint_output):\n",
    "        if not self.hasArchitecture:\n",
    "            self.create_architecture()\n",
    "        \n",
    "        cp_path = checkpoint_output\n",
    "        model_path = os.path.join(cp_path,self.model.name)\n",
    "        #save model to another directory if directory already exists \n",
    "        i=1\n",
    "        while (os.path.exists(model_path)):\n",
    "            model_path=os.path.join(model_path,\"v_{}\".format(i))\n",
    "        os.mkdir(model_path)\n",
    "        cp_format = os.path.join(model_path, \"unet-{epoch:02d}.hdf5\")\n",
    "        \n",
    "        cp_callback = ModelCheckpoint(\n",
    "        #save checkpoints at every epoch\n",
    "        cp_format, save_freq='epoch')\n",
    "\n",
    "        print(\"Network checkpoints will be saved to: '{}'\".format(cp_path))\n",
    "\n",
    "        self.history = self.model.fit(\n",
    "        subsampled,\n",
    "        original,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_ephocs,\n",
    "        shuffle=True,\n",
    "        validation_split=.2,\n",
    "        callbacks=[cp_callback]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.model.save(model_path) \n",
    "         \n",
    "    \n",
    "    \n",
    "    def create_architecture(self):\n",
    "        inputs = Input(shape=(dataset_shape,dataset_column,1))\n",
    "        \n",
    "        weights_init = RandomNormal(mean=0.0,stddev=0.1)\n",
    "        \n",
    "        #using padding = same is zero padding\n",
    "        zeroPadding = \"same\"\n",
    "        \n",
    "        layer1 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(inputs)\n",
    "        \n",
    "        layer2 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(layer1)\n",
    "        \n",
    "        maxpool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(layer2)\n",
    "        \n",
    "        layer3 = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(maxpool1)\n",
    "        \n",
    "        layer4 = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(layer3)\n",
    "        \n",
    "        maxpool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(layer4)\n",
    "        \n",
    "        layer5 = Conv2D(\n",
    "            filters=256,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(maxpool2)\n",
    "        \n",
    "        layer6 = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(layer5)\n",
    "        \n",
    "        averagepool1 =  concatenate([UpSampling2D(size=(2, 2))(layer6), layer4], axis=3)        \n",
    "        \n",
    "        layer7 = Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(averagepool1)\n",
    "        \n",
    "        layer8 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(layer7)\n",
    "        \n",
    "        averagepool2 = concatenate([UpSampling2D(size=(2, 2))(layer8), layer2], axis=3)\n",
    "        \n",
    "        layer9 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(averagepool2)\n",
    "        \n",
    "        layer10 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer=weights_init)(layer9)\n",
    "        \n",
    "        finalOutput = Conv2D(\n",
    "            filters=1,\n",
    "            kernel_size=self.kernels,\n",
    "            strides=self.strides,\n",
    "            padding=zeroPadding,\n",
    "            activation=None,\n",
    "            kernel_initializer=weights_init)(layer10)\n",
    "        \n",
    "        self.model = Model(inputs=[inputs], outputs=[finalOutput])\n",
    "        \n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=RMSprop( lr=.001, rho=0.9, epsilon=1e-08, decay=0),\n",
    "            loss=mean_squared_error,\n",
    "            metrics=[mean_squared_error])\n",
    "\n",
    "        self.hasArchitecture = True\n",
    "\n",
    "    def reconstruct(self,undersampled_img):\n",
    "        return self.model.predict(undersampled_img)\n",
    "    \n",
    "    def plot_model(self,metric):\n",
    "        plt.plot(self.history.history[metric])\n",
    "        plt.title(metric)\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xscale( \"log\")\n",
    "        return self.history\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 320, 320, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 320, 320, 64) 640         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 320, 320, 64) 36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 160, 160, 64) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 160, 160, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 160, 160, 128 147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 80, 80, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 80, 80, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 80, 80, 128)  295040      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 160, 160, 128 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 160, 160, 256 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 160, 160, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 160, 160, 64) 73792       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 320, 320, 64) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 320, 320, 128 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 320, 320, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 320, 320, 64) 36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 320, 320, 1)  577         conv2d_20[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,329,345\n",
      "Trainable params: 1,329,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Network checkpoints will be saved to: 'C:/MRI_dataset/output'\n",
      "Epoch 1/2000\n"
     ]
    }
   ],
   "source": [
    "#Specify prefered AFs\n",
    "AF=[1,2,3,4]\n",
    "original,subsampled = loadImages(datasets,AF)\n",
    "\n",
    "#Intialise model with prefered Activation Function\n",
    "net = uNet('relu')\n",
    "\n",
    "#Intialise batch size, number of epochs and output directory\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "modelOutputDirectory = 'C:/MRI_dataset/output'\n",
    "\n",
    "#Train Model\n",
    "net.train(subsampled,original,batch_size,epochs,modelOutputDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following contains the code for reconstruction, error fixing and image/mse plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval():\n",
    "    def __init__(self,model):\n",
    "        m=uNet('relu')\n",
    "        m.set_model(model)\n",
    "        self.model = m\n",
    "        \n",
    "    def undersample_dataset(self,dataset,AF):\n",
    "        #edge cases \n",
    "        if not dataset:\n",
    "            raise Exception(\"Input a valid dataset\")\n",
    "\n",
    "        if not AF: \n",
    "            raise Exception(\"Enter an accelaration factor\")\n",
    "\n",
    "        if any ((x>4 or x<0) for x in AF):\n",
    "            raise Exception(\"The model only trains accelaration factors in the range of x where 0 <= x <= 4\")\n",
    "\n",
    "        undersampled_imgs ={}\n",
    "\n",
    "        for i in range(len(dataset)):\n",
    "            for j in range(len(AF)):\n",
    "                x = {\"{img}{AF}\".format(img=i , AF = AF[j]):np.absolute(inverseFourierTransform(dataset[i].grappaUndersample(AF[j],20)))\n",
    "                }\n",
    "                undersampled_imgs.update(x)\n",
    "\n",
    "        return undersampled_imgs\n",
    "    \n",
    "    def reconstruct(self,undersampled_img):\n",
    "        undersampled_input = undersampled_img.reshape(1,dataset_shape,dataset_shape,1)\n",
    "        recon_output = self.model.reconstruct(undersampled_input)\n",
    "        return np.squeeze(recon_output)\n",
    "    \n",
    "    def k_space_Correction(self,recon_img,original_img):\n",
    "        recon_fft = fourierTransform(recon_img)\n",
    "        original_fft = fourierTransform(original_img)\n",
    "\n",
    "        center_line = int(len(recon_fft)/2)\n",
    "\n",
    "        centerline_factor = 20\n",
    "\n",
    "        upper_border = int(center_line - ( centerline_factor)/2)\n",
    "        lower_border = int(center_line + ( centerline_factor)/2)\n",
    "\n",
    "        #Fix k-space of recon Image\n",
    "        recon_upper = recon_fft[0:upper_border]\n",
    "        recon_lower = recon_fft[lower_border+1:]\n",
    "        recon_centre = original_fft[upper_border:lower_border+1]\n",
    "        recon_fixed = np.concatenate((recon_upper,recon_centre ,recon_lower))\n",
    "\n",
    "        return np.absolute(inverseFourierTransform(recon_fixed))\n",
    "    \n",
    "    \n",
    "    #Plot MSE between recon Img and original Img\n",
    "    def plot_MSE(self,dataset,AF):\n",
    "        undersampled_imgs = self.undersample_dataset(dataset,AF)\n",
    "\n",
    "\n",
    "        k=0\n",
    "        for i,j in undersampled_imgs.items():\n",
    "\n",
    "            x = self.reconstruct(j)\n",
    "            y=dataset[k].get_Image()\n",
    "            \n",
    "            #Writes MSE to the console\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            print(\"Image {a} AF {b}\".format(a=k,b=i[len(i)-1]))\n",
    "            print(mse(y, x).numpy())\n",
    "\n",
    "\n",
    "            if(int(i[len(i)-1])==4):\n",
    "                k+=1\n",
    "        \n",
    "    #plot mse between recon img and k-space fixed recon img \n",
    "    def plot_kspace_fix_MSE(self,dataset,AF):\n",
    "        undersampled_imgs = self.undersample_dataset(dataset,AF)\n",
    "\n",
    "\n",
    "        k=0\n",
    "        for i,j in undersampled_imgs.items():\n",
    "\n",
    "            x = self.reconstruct(j)\n",
    "            y=dataset[k].get_Image()\n",
    "            x= self.k_space_Correction(x,y)\n",
    "\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            print(\"Image {a} AF {b}\".format(a=k,b=i[len(i)-1]))\n",
    "            print(mse(y, x).numpy())\n",
    "\n",
    "\n",
    "            if(int(i[len(i)-1])==4):\n",
    "                k+=1\n",
    "    \n",
    "    #plots undersampled images with reconstructed figures\n",
    "    def plot_imgs(self,dataset,AF,output_dir):\n",
    "        undersampled_imgs = self.undersample_dataset(dataset,AF)\n",
    "        directory = net.model.name\n",
    "\n",
    "        # Path \n",
    "        path = os.path.join(output_dir, directory)\n",
    "        if not os.path.exists(path):  \n",
    "            os.mkdir(path)\n",
    "        else:\n",
    "            z=1\n",
    "            while os.path.exists(path):\n",
    "                path = os.path.join(path,\"v{}\".format(z))\n",
    "\n",
    "        os.mkdir(path)\n",
    "\n",
    "        print(\"Images saved at '% s' \" % path)\n",
    "\n",
    "        k=0\n",
    "        for i,j in undersampled_imgs.items():\n",
    "\n",
    "            reconstructed_img = self.reconstruct(j)\n",
    "            print()\n",
    "\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.subplot(121), plt.imshow(j, cmap=plt.cm.bone) \n",
    "            plt.title(\"Undersampled Image {img} at AF={af}\".format(img=k,af=i[len(i)-1]),fontsize=25)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(122), plt.imshow(reconstructed_img, cmap=plt.cm.bone)\n",
    "            plt.title('Reconstructed Image',fontsize=25)\n",
    "            plt.axis('off')\n",
    "\n",
    "            save_img = os.path.join(path, \"{}.png\".format(\"{}\".format(i)))\n",
    "            plt.savefig(save_img, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Saved {index} to {path}\".format(\n",
    "                index=i, path=save_img))\n",
    "            if(int(i[len(i)-1])==4):\n",
    "                k+=1\n",
    "                \n",
    "    #plot reconstructed images with k-space fixed recon img\n",
    "    def plot_k_spaceFix_imgs(dataset,AF,output_dir):\n",
    "        undersampled_imgs = self.undersample_dataset(dataset,AF)\n",
    "        directory = net.model.name\n",
    "\n",
    "        # Path \n",
    "        path = os.path.join(output_dir, directory)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "            z=1\n",
    "            while os.path.exists(path):\n",
    "                path = os.path.join(path,\"v{}\".format(z))\n",
    "\n",
    "        os.mkdir(path)\n",
    "\n",
    "        print(\"Images saved at '% s' \" % path)\n",
    "\n",
    "        k=0\n",
    "        for i,j in undersampled_imgs.items():\n",
    "\n",
    "            reconstructed_img = self.reconstruct(j)\n",
    "            print()\n",
    "\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.subplot(121), plt.imshow(reconstructed_img, cmap=plt.cm.bone) \n",
    "            plt.title(\"Reconstructed Validation Image {img} at AF={af}\".format(img=k+14,af=i[len(i)-1]),fontsize=25)\n",
    "            plt.axis('off')\n",
    "\n",
    "            y=dataset[k].get_Image()\n",
    "            k_space_fix = self.k_space_Correction(reconstructed_img,y)\n",
    "\n",
    "            plt.subplot(122), plt.imshow(k_space_fix, cmap=plt.cm.bone)\n",
    "            plt.title('k-space fixed Image',fontsize=25)\n",
    "            plt.axis('off')\n",
    "\n",
    "            save_img = os.path.join(path, \"{}.png\".format(\"{}\".format(i)))\n",
    "            plt.savefig(save_img, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Saved {index} to {path}\".format(\n",
    "                index=i, path=save_img))\n",
    "            if(int(i[len(i)-1])==4):\n",
    "                k+=1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
